quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true
quarkus.langchain4j.chat-model.provider=ollama

quarkus.langchain4j.ollama.chat-model.model-id=qwen3:8b
quarkus.langchain4j.ollama.chat-model.temperature=0.3
quarkus.langchain4j.ollama.timeout=180s