quarkus.http.port=8080
quarkus.application.name=niby-be


quarkus.langchain4j.chat-model.provider=anthropic
#
#quarkus.langchain4j.ollama.chat-model.model-id=gpt-oss:20b
#quarkus.langchain4j.ollama.chat-model.temperature=0.7
#quarkus.langchain4j.ollama.timeout=1000s




# Abilita CORS globalmente
quarkus.http.cors=true

# (Opzionale) Limita solo a niby-ui
quarkus.http.cors.origins=http://localhost:8081

# (Opzionale) Metodi ammessi
quarkus.http.cors.methods=GET,POST,PUT,DELETE,OPTIONS

# (Opzionale) Headers ammessi
quarkus.http.cors.headers=accept,authorization,content-type,x-requested-with

# Enable WebSocket CORS for cross-origin connections
quarkus.websockets-next.server.cors.origins=http://localhost:8081



quarkus.log.console.format=%d{HH:mm:ss} %-5p [%c{2.}] (%t) %s%e%n

# File logging configuration
quarkus.log.file.enable=true
quarkus.log.file.path=logs/niby-be.log
quarkus.log.file.format=%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%c{3.}] (%t) %s%e%n
quarkus.log.file.rotation.max-file-size=10M
quarkus.log.file.rotation.max-backup-index=5

# Set log level for WebSocket class to see INFO and DEBUG messages
quarkus.log.category."cloud.isaura.niby".level=DEBUG

# Enable detailed LangChain4j logging
quarkus.log.category."dev.langchain4j".level=DEBUG
quarkus.log.category."io.quarkiverse.langchain4j".level=DEBUG

quarkus.langchain4j.anthropic.chat-model.model-name=claude-sonnet-4-5-20250929
quarkus.langchain4j.anthropic.api-key=${ANTHROPIC_API_KEY}
quarkus.langchain4j.anthropic.log-requests=true
quarkus.langchain4j.anthropic.log-responses=true